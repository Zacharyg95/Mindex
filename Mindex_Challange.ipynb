{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import IntegerType\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the s3 Session with provided keys\n",
    "s3 = boto3.Session(\n",
    "    aws_access_key_id='AKIAZZ33YB65GZIN656A',\n",
    "    aws_secret_access_key='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',\n",
    ").client('s3')\n",
    "\n",
    "#Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Mindex_Challange\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Create variable to store bucket name for all files\n",
    "s3_bucket_name = 'mindex-data-analytics-code-challenge'\n",
    "\n",
    "#Download fiels loacally from s3 bucket\n",
    "s3.download_file(s3_bucket_name, 'bengals.csv', 'bengals.csv')\n",
    "s3.download_file(s3_bucket_name, 'boyd_receiving.csv', 'boyd_receiving.csv')\n",
    "s3.download_file(s3_bucket_name, 'chase_receiving.csv', 'chase_receiving.csv')\n",
    "s3.download_file(s3_bucket_name, 'higgins_receiving.csv', 'higgins_receiving.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in files from local\n",
    "bengals = spark.read.option(\"header\",True).csv(\"bengals.csv\")\n",
    "boyd = spark.read.option(\"header\",True).csv(\"boyd_receiving.csv\")\n",
    "chase = spark.read.option(\"header\",True).csv(\"chase_receiving.csv\")\n",
    "higgins = spark.read.option(\"header\",True).csv(\"higgins_receiving.csv\")\n",
    "\n",
    "#Join all data sets into one, use left joins to include all preseason games and any games the players missed\n",
    "#Rename commonly named columsn to still make distinction\n",
    "master_df = bengals.join(boyd.withColumnRenamed('Yards','boyd_yards').withColumnRenamed('TD','boyd_td'), on=['Week'], how='left')\\\n",
    "                   .join(chase.withColumnRenamed('Yards','chase_yards').withColumnRenamed('TD','chase_td'), on=['Week'], how='left')\\\n",
    "                   .join(higgins.withColumnRenamed('Yards','higgins_yards').withColumnRenamed('TD','higgins_td'), on=['Week'], how='left')\n",
    "\n",
    "#Data Transformations, replace any nulls values with 0s\n",
    "master_df = master_df.withColumn('Result', f.when(f.col('Result') == 1, f.lit('Win')).otherwise(f.lit('Loss')))\\\n",
    "                     .withColumn('boyd_yards', f.when(f.col('boyd_yards').isNull(), f.lit(0)).otherwise(f.col('boyd_yards')))\\\n",
    "                     .withColumn('boyd_td', f.when(f.col('boyd_td').isNull(), f.lit(0)).otherwise(f.col('boyd_td')))\\\n",
    "                     .withColumn('chase_yards', f.when(f.col('chase_yards').isNull(), f.lit(0)).otherwise(f.col('chase_yards')))\\\n",
    "                     .withColumn('chase_td', f.when(f.col('chase_td').isNull(), f.lit(0)).otherwise(f.col('chase_td')))\\\n",
    "                     .withColumn('higgins_yards', f.when(f.col('higgins_yards').isNull(), f.lit(0)).otherwise(f.col('higgins_yards')))\\\n",
    "                     .withColumn('higgins_td', f.when(f.col('higgins_td').isNull(), f.lit(0)).otherwise(f.col('higgins_td')))\n",
    "\n",
    "#Convert number columns to Integers before we prepare to write to DB\n",
    "for c in master_df.columns:\n",
    "    if 'yards' in c or 'td' in c:\n",
    "        master_df = master_df.withColumn(str(c), f.col(str(c)).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Connection Parameters String to pass into psycopg2 conection function\n",
    "conn_params = \"host='ls-2619b6b15c9bdc80a23f6afb7eee54cf0247da21.ca3yee6xneaj.us-east-1.rds.amazonaws.com'\\\n",
    "               dbname='postgres'\\\n",
    "               user='zachary_gay'\\\n",
    "               password='gacharyzay'\"\n",
    "\n",
    "#Create empty variable to be referenced during all steps of the try-excpet-finally\n",
    "db_conn = None\n",
    "table_name = 'zachary_gay'\n",
    "try:\n",
    "    #Attempt connect to the DB\n",
    "    db_conn = psycopg2.connect(conn_params)\n",
    "    #If the connection was successful\n",
    "    if db_conn:\n",
    "        #create engine to begin inserting data to DB\n",
    "        engine = create_engine('postgresql+psycopg2://zachary_gay:gacharyzay@ls-2619b6b15c9bdc80a23f6afb7eee54cf0247da21.ca3yee6xneaj.us-east-1.rds.amazonaws.com:5432/postgres')\n",
    "        #Convert Pysaprk df to Pandas in order to utilize the to_sql(), set the function to drop the table before inserting new records since records in the app are always the same\n",
    "        master_df.toPandas().to_sql(table_name, engine, if_exists='replace', index=False)    \n",
    "        \n",
    "except (Exception, psycopg2.Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "\n",
    "finally:\n",
    "    #If we connected to the DB then close the conenction\n",
    "    if db_conn:\n",
    "        db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
